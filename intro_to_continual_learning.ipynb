{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "intro_to_continual_learning.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/ContinualAI/colab/blob/master/intro_to_continual_learning.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "fp9hbokQIxWW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# A Gentle Introduction to Continual Learning in PyTorch\n",
        "\n",
        "In this brief tutorial we will learn the basics of *Continual Learning* using *Pytorch 0.4.0*. We will use the standard MNIST benchmark so that you can swiftly run this notebook from anywhere!\n",
        "\n",
        "This notebook is part of the **[Continual AI Colab](https://github.com/ContinualAI/colab)** is a repository meant for tutorials and demo running on Google Colaboratory. [Continual AI](https://www.continualai.org/) is an open research community on the topic of Continual Learning and AI! Join us today [on slack](https://continualai.herokuapp.com/)! :-D\n",
        "\n",
        "We will start with learning over the standard *MNIST* benchmark, then we will move in the actual continual learning setting  with the *Permuted MNIST* benchmark. Let's have some fun! :-)\n",
        "\n",
        "\n",
        "---\n",
        "** Connecting a local runtime**\n",
        "\n",
        "In case resources are not enough for you (no GPU for example), you can always connect another [local runtime](https://research.google.com/colaboratory/local-runtimes.html) or to a [runtime on a Google Compute Engine instance](https://research.google.com/colaboratory/local-runtimes.html).\n",
        "\n",
        "This notebook has been designed to run fast enough on simple CPUs so you shouldn't fined any trouble here, using a free *hosted account*.\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "**Requisites to run it locally, outside colab (not recommended)**\n",
        "\n",
        "*   Python 3.x\n",
        "*   Jupyter\n",
        "*   Pytorch 0.4.0\n",
        "*   Numpy\n",
        "*   Matplolib\n",
        "---\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "z6RUp96FLuMd",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Google Colaboratory\n",
        "\n",
        "First of all, take a moment to look around and discover Google Colab if you haven't before! You can run the commands below to understand how much resources you're using and are still available. Then consider also that you can also connect you Google Drive for additional space or for easily loading your own files.\n",
        "\n",
        "You can always reset the entire VM with \"*Runtime > Reset all runtime*\" in case of difficulty. Make also sure you're using the GPU or TPU in the same  tab (\"*Runtime > Change runtime type*\")."
      ]
    },
    {
      "metadata": {
        "id": "pPViRmMBqbJ2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 521
        },
        "outputId": "3451a300-c541-4d6a-b2b9-3f0ee6c23335"
      },
      "cell_type": "code",
      "source": [
        "!free -m\n",
        "!df -h\n",
        "!nvidia-smi"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              total        used        free      shared  buff/cache   available\n",
            "Mem:          13022         369       11088         248        1564       12161\n",
            "Swap:             0           0           0\n",
            "Filesystem      Size  Used Avail Use% Mounted on\n",
            "overlay         359G  9.8G  331G   3% /\n",
            "tmpfs           6.4G     0  6.4G   0% /dev\n",
            "tmpfs           6.4G     0  6.4G   0% /sys/fs/cgroup\n",
            "tmpfs           6.4G  249M  6.2G   4% /opt/bin\n",
            "/dev/sda1       365G   12G  354G   4% /etc/hosts\n",
            "shm              64M     0   64M   0% /dev/shm\n",
            "tmpfs           6.4G     0  6.4G   0% /sys/firmware\n",
            "Sun Sep 30 13:50:26 2018       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 384.111                Driver Version: 384.111                   |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   31C    P8    26W / 149W |      0MiB / 11439MiB |      0%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                       GPU Memory |\n",
            "|  GPU       PID   Type   Process name                             Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "jt_PxOYPmxp_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Questions to explore:**\n",
        "\n",
        "*   How to connect your Google Drive with Google Colab?\n",
        "*   How to import a new notebook and save it to your GDrive?\n",
        "*   How to use files which are contained in your GDrive?\n",
        "\n",
        "Some tips here: https://medium.com/deep-learning-turkey/google-colab-free-gpu-tutorial-e113627b9f5d\n"
      ]
    },
    {
      "metadata": {
        "id": "eaSUr-B3NEZq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Intalling Pytorch 0.4.0\n",
        "\n",
        "Tensorflow is installed by default in Google Colab (guess why :P). If you want to use another DL toolkit you have to do it by yourself. Run the command below to install it. It should take less than a couple of minutes."
      ]
    },
    {
      "metadata": {
        "id": "herKnlqYGYdx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        },
        "outputId": "2ed869ed-8009-407d-e837-b636d9937eed"
      },
      "cell_type": "code",
      "source": [
        "# http://pytorch.org/\n",
        "from os import path\n",
        "from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
        "platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
        "\n",
        "accelerator = 'cu80' #'cu80' if path.exists('/opt/bin/nvidia-smi') else 'cpu'\n",
        "print('Platform:', platform, 'Accelerator:', accelerator)\n",
        "\n",
        "!pip install --upgrade --force-reinstall -q http://download.pytorch.org/whl/{accelerator}/torch-0.4.0-{platform}-linux_x86_64.whl torchvision\n",
        "\n",
        "import torch\n",
        "print('Torch', torch.__version__, 'CUDA', torch.version.cuda)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Platform: cp36-cp36m Accelerator: cu80\n",
            "tcmalloc: large alloc 1073750016 bytes == 0x5c03e000 @  0x7f5f4fb251c4 0x46d6a4 0x5fcbcc 0x4c494d 0x54f3c4 0x553aaf 0x54e4c8 0x54f4f6 0x553aaf 0x54efc1 0x54f24d 0x553aaf 0x54efc1 0x54f24d 0x553aaf 0x54efc1 0x54f24d 0x551ee0 0x54e4c8 0x54f4f6 0x553aaf 0x54efc1 0x54f24d 0x551ee0 0x54efc1 0x54f24d 0x551ee0 0x54e4c8 0x54f4f6 0x553aaf 0x54e4c8\n",
            "Torch 0.4.0 CUDA 8.0.61\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "i74kZQufNv5d",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Ok, torch is installed and imported! Let' see if it can see the GPU:"
      ]
    },
    {
      "metadata": {
        "id": "hv7FUJ2Wrd_l",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "605b1515-79b6-418b-a71c-7482974b9248"
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "torch.cuda.is_available()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "metadata": {
        "id": "JuSqVkPnN7iT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "That's great, let us import then a few libraries, which we'll be using during this tutorial!"
      ]
    },
    {
      "metadata": {
        "id": "w7AxhUWe68vT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nGL7z5R2oxrX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Questions to explore:**\n",
        "\n",
        "*   What's new in Pythorch 0.4?\n",
        "\n",
        "Some tips here: https://pytorch.org/blog/pytorch-0_4_0-migration-guide/\n"
      ]
    },
    {
      "metadata": {
        "id": "rv89m9nBPXSh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## MNIST: Digits recognition with PyTorch \n",
        "\n",
        "All right, let's start then making sure we all know the basic! Let's recognize the ten handwritten digits learning from 60.000, 28x28 grayscale images.\n",
        "For simplicity let's import a loading script we have already developed inside the **Continual AI Colab** repository:"
      ]
    },
    {
      "metadata": {
        "id": "yKWbcnh474X3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "outputId": "7cd2e7b0-ef07-46c3-9f05-9343ba194945"
      },
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/ContinualAI/colab.git"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'colab'...\n",
            "remote: Enumerating objects: 43, done.\u001b[K\n",
            "remote: Counting objects: 100% (43/43), done.\u001b[K\n",
            "remote: Compressing objects: 100% (38/38), done.\u001b[K\n",
            "remote: Total 43 (delta 11), reused 9 (delta 2), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (43/43), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "x3BFVukM_y8i",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "outputId": "93942f8d-cb56-4daf-8044-047908a579ce"
      },
      "cell_type": "code",
      "source": [
        "from colab.scripts import mnist\n",
        "mnist.init()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading train-images-idx3-ubyte.gz...\n",
            "Downloading t10k-images-idx3-ubyte.gz...\n",
            "Downloading train-labels-idx1-ubyte.gz...\n",
            "Downloading t10k-labels-idx1-ubyte.gz...\n",
            "Download complete.\n",
            "Save complete.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "6jIk6-G6AhWi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "25c6864b-df26-49a1-a8e4-049705b129d4"
      },
      "cell_type": "code",
      "source": [
        "x_train, t_train, x_test, t_test = mnist.load()\n",
        "\n",
        "print(\"x_train dim and type: \", x_train.shape, x_train.dtype)\n",
        "print(\"t_train dim and type: \", t_train.shape, t_train.dtype)\n",
        "print(\"x_test dim and type: \", x_test.shape, x_test.dtype)\n",
        "print(\"t_test dim and type: \", t_test.shape, t_test.dtype)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_train dim and type:  (60000, 1, 28, 28) float32\n",
            "t_train dim and type:  (60000,) uint8\n",
            "x_test dim and type:  (10000, 1, 28, 28) float32\n",
            "t_test dim and type:  (10000,) uint8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "XEWG2PmbVvb7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Let's take a look at the actual images!"
      ]
    },
    {
      "metadata": {
        "id": "RyIuYAw8AuO6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 348
        },
        "outputId": "48937ba1-7253-4198-ecf4-bc58b6ca54af"
      },
      "cell_type": "code",
      "source": [
        "f, axarr = plt.subplots(2,2)\n",
        "axarr[0,0].imshow(x_train[1, 0], cmap=\"gray\")\n",
        "axarr[0,1].imshow(x_train[2, 0], cmap=\"gray\")\n",
        "axarr[1,0].imshow(x_train[3, 0], cmap=\"gray\")\n",
        "axarr[1,1].imshow(x_train[4, 0], cmap=\"gray\")\n",
        "np.vectorize(lambda ax:ax.axis('off'))(axarr);"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZwAAAFLCAYAAADiejquAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f6fff0c3c50>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "baEsU4PGXsgS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Good! Let's now set up a few general setting before using torch..."
      ]
    },
    {
      "metadata": {
        "id": "ztZAPQNXZ4ll",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# switch to False to use CPU\n",
        "use_cuda = True\n",
        "\n",
        "use_cuda = use_cuda and torch.cuda.is_available()\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\");\n",
        "torch.manual_seed(1);"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0Ek0mErIac6n",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "... and define our first conv-net! We will use 3 layers of convolutions and two fully connected layers:"
      ]
    },
    {
      "metadata": {
        "id": "ONMdybG4Be0z",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
        "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
        "        self.conv2_drop = nn.Dropout2d()\n",
        "        self.fc1 = nn.Linear(320, 50)\n",
        "        self.fc2 = nn.Linear(50, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
        "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
        "        x = x.view(-1, 320)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.dropout(x, training=self.training)\n",
        "        x = self.fc2(x)\n",
        "        return F.log_softmax(x, dim=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "p9S6a-MlYAsu",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Then we can write the *train* and *test* functions. Note that for simplicity here we are not using Pytorch [Data Loaders](https://pytorch.org/tutorials/beginner/data_loading_tutorial.html) but this is not recommended for efficiency."
      ]
    },
    {
      "metadata": {
        "id": "HGJJfXhJB-zk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def train(model, device, x_train, t_train, optimizer, epoch):\n",
        "    model.train()\n",
        "    \n",
        "    for start in range(0, len(t_train)-1, 256):\n",
        "      end = start + 256\n",
        "      x, y = torch.from_numpy(x_train[start:end]), torch.from_numpy(t_train[start:end]).long()\n",
        "      x, y = x.to(device), y.to(device)\n",
        "      \n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      output = model(x)\n",
        "      loss = F.cross_entropy(output, y)\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      #print(loss.item())\n",
        "    print('Train Epoch: {} \\tLoss: {:.6f}'.format(epoch, loss.item()))\n",
        "\n",
        "def test(model, device, x_test, t_test):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    for start in range(0, len(t_test)-1, 256):\n",
        "      end = start + 256\n",
        "      with torch.no_grad():\n",
        "        x, y = torch.from_numpy(x_test[start:end]), torch.from_numpy(t_test[start:end]).long()\n",
        "        x, y = x.to(device), y.to(device)\n",
        "        output = model(x)\n",
        "        test_loss += F.cross_entropy(output, y).item() # sum up batch loss\n",
        "        pred = output.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
        "        correct += pred.eq(y.view_as(pred)).sum().item()\n",
        "\n",
        "    test_loss /= len(t_train)\n",
        "    print('Test set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "        test_loss, correct, len(t_test),\n",
        "        100. * correct / len(t_test)))\n",
        "    return 100. * correct / len(t_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IxIISdDPaqb9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Then we are ready to instantiate our model and start the training!"
      ]
    },
    {
      "metadata": {
        "id": "1cJURe0JCFh8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = Net().to(device)\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BlhVt8vylpUv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "outputId": "9f234bbc-ac81-4773-f957-d26a27a509f1"
      },
      "cell_type": "code",
      "source": [
        "for epoch in range(1, 3):\n",
        "  train(model, device, x_train, t_train, optimizer, epoch)\n",
        "  test(model, device, x_test, t_test)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Epoch: 1 \tLoss: 0.779770\n",
            "Test set: Average loss: 0.0002, Accuracy: 8980/10000 (90%)\n",
            "\n",
            "Train Epoch: 2 \tLoss: 0.467472\n",
            "Test set: Average loss: 0.0001, Accuracy: 9426/10000 (94%)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "7qwh4T5Va86-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Wow! 94% accuracy in such a short time. \n",
        "\n",
        "**Questions to explore:**\n",
        "\n",
        "*   Can you find a better parametrization to improve the final accuracy?\n",
        "*   Can you change the network architecture to improve the final accuracy?\n",
        "*   Can you achieve the same performances with a smaller architecture?\n",
        "*   What's the difference in accuracy if you change convolutions with fully connected layers?\n",
        "\n",
        "Some tips here: http://rodrigob.github.io/are_we_there_yet/build/classification_datasets_results.html#4d4e495354"
      ]
    },
    {
      "metadata": {
        "id": "2dn-5gOGq08g",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "But what if now we want we the same model being able to solve a new task we encounter over time like a permuted version of the same MNIST? Let's define our custom function to permute it!"
      ]
    },
    {
      "metadata": {
        "id": "6Xq_4UvjgXPQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def permute_mnist(mnist, seed):\n",
        "    \"\"\" Given the training set, permute pixels of each img the same way. \"\"\"\n",
        "\n",
        "    np.random.seed(seed)\n",
        "    print(\"starting permutation...\")\n",
        "    h = w = 28\n",
        "    perm_inds = list(range(h*w))\n",
        "    np.random.shuffle(perm_inds)\n",
        "    # print(perm_inds)\n",
        "    perm_mnist = []\n",
        "    for set in mnist:\n",
        "        num_img = set.shape[0]\n",
        "        flat_set = set.reshape(num_img, w * h)\n",
        "        perm_mnist.append(flat_set[:, perm_inds].reshape(num_img, 1, w, h))\n",
        "    print(\"done.\")\n",
        "    return perm_mnist"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4xG5LFwLgkpu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "6b064720-09b2-40a4-bb52-cbc12685cad3"
      },
      "cell_type": "code",
      "source": [
        "x_train2, x_test2 = permute_mnist([x_train, x_test], 0)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "starting permutation...\n",
            "done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "LYBa_Gedh_do",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 251
        },
        "outputId": "e6c6dbd2-4db1-4ea7-e5d0-92c1b9c2b39b"
      },
      "cell_type": "code",
      "source": [
        "f, axarr = plt.subplots(1,2)\n",
        "axarr[0].imshow(x_train[1, 0], cmap=\"gray\")\n",
        "axarr[1].imshow(x_train2[2, 0], cmap=\"gray\")\n",
        "np.vectorize(lambda ax:ax.axis('off'))(axarr);"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAd8AAADqCAYAAADjwE/yAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nU74AEOx/lvsXlcSMKS4AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f6fff0ae7b8>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "46wHcbNAchH-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Amazing. Now let's see how our pre-trained model is working on both the original and the permuted MNIST dataset:"
      ]
    },
    {
      "metadata": {
        "id": "Sxusb8s3itli",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "outputId": "9d6e8172-c330-4768-d26b-b5e1d38243c9"
      },
      "cell_type": "code",
      "source": [
        "print(\"Testing on the first task:\")\n",
        "test(model, device, x_test, t_test)\n",
        "\n",
        "print(\"Testing on the second task:\")\n",
        "test(model, device, x_test2, t_test);"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Testing on the first task:\n",
            "Test set: Average loss: 0.0001, Accuracy: 9426/10000 (94%)\n",
            "\n",
            "Testing on the second task:\n",
            "Test set: Average loss: 0.0018, Accuracy: 1068/10000 (11%)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "0pHMg4G_dHFY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Mmmh... that's pretty bad, our model cannot generalize to this apparently very different new task! Well, we can just finetune our model using the new permuted training set!"
      ]
    },
    {
      "metadata": {
        "id": "J5PtR8Gqib00",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "outputId": "3d6f99cc-c3f0-4718-8555-d642e6276623"
      },
      "cell_type": "code",
      "source": [
        "for epoch in range(1, 3):\n",
        "  train(model, device, x_train2, t_train, optimizer, epoch)\n",
        "  test(model, device, x_test2, t_test)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Epoch: 1 \tLoss: 1.522812\n",
            "Test set: Average loss: 0.0005, Accuracy: 7400/10000 (74%)\n",
            "\n",
            "Train Epoch: 2 \tLoss: 1.273886\n",
            "Test set: Average loss: 0.0004, Accuracy: 8289/10000 (83%)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ML7Evzb9jPAZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "outputId": "d9d6cc71-a7ea-40dd-f5f1-ae4d5bc336a5"
      },
      "cell_type": "code",
      "source": [
        "print(\"Testing on the first task:\")\n",
        "test(model, device, x_test, t_test)\n",
        "\n",
        "print(\"Testing on the second task:\")\n",
        "test(model, device, x_test2, t_test);"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Testing on the first task:\n",
            "Test set: Average loss: 0.0029, Accuracy: 2792/10000 (28%)\n",
            "\n",
            "Testing on the second task:\n",
            "Test set: Average loss: 0.0004, Accuracy: 8289/10000 (83%)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "0UZ6FBuHdm7N",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "This is very annoying! Now we are not able to solve the original MNSIT task anymore! :-( This is the phenomenon known in literature as **Catastrophic Forgetting**! In the following section we well compare three different strategies for learning continually (and trying to not forget!)\n",
        "\n",
        "**Questions to explore:**\n",
        "\n",
        "*   When the permuted MNIST benchmark has been firstly introduced? \n",
        "*   Can simple Dropout and Regularization techniques reduce forgetting?\n",
        "*   In the permuted MNIT task, do convolutions still help increasing the accuracy?\n",
        "\n",
        "Some tips here: https://papers.nips.cc/paper/5059-compete-to-compute"
      ]
    },
    {
      "metadata": {
        "id": "9rUgLpUakTy6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## CL Strategies\n",
        "\n",
        "Let us now focus on some strategies for reducing catastrofic forgetting, one of the principal problems when learning continuously. in this section we will take a look at three different strategies:\n",
        "\n",
        "1.   Naive\n",
        "2.   Rehearsal\n",
        "3.   Elastic Weight Consolidation (EWC)\n",
        "\n",
        "and run it on a 3-tasks Permuted MNIST. Finally we will plot our results for comparison. For a more comprehensive overview on recent CL strategies for deep learning take a look at the recent paper \"[Continuous Learning in Single-Incremental-Task Scenarios](https://arxiv.org/abs/1806.08568)\".\n",
        "\n",
        "Let's start by defining our 3 tasks with the function we have already introduced before:\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "Yu0T_V24joGY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "d7e2cf81-9c2b-4f30-92d6-0292d7f162ea"
      },
      "cell_type": "code",
      "source": [
        "# task 1\n",
        "task_1 = [(x_train, t_train), (x_test, t_test)]\n",
        "\n",
        "# task 2\n",
        "x_train2, x_test2 = permute_mnist([x_train, x_test], 1)\n",
        "task_2 = [(x_train2, t_train), (x_test2, t_test)]\n",
        "\n",
        "# task 3\n",
        "x_train3, x_test3 = permute_mnist([x_train, x_test], 2)\n",
        "task_3 = [(x_train3, t_train), (x_test3, t_test)]\n",
        "\n",
        "# task list\n",
        "tasks = [task_1, task_2, task_3]"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "starting permutation...\n",
            "done.\n",
            "starting permutation...\n",
            "done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "yUNaukXyiJni",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Naive Strategy\n",
        "\n",
        "The  *Naive* strategy, is the simple idea of continuing the back-prop process on the new batches/tasks. This is very simple, but at the same time very prone to forgetting as we have witnessed before. Let's how it works on three tasks:"
      ]
    },
    {
      "metadata": {
        "id": "gzFEA5F8pI_O",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = Net().to(device)\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dLU6KdIbnLMN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 665
        },
        "outputId": "a40235bf-c835-497b-8dd4-8f931d566d1c"
      },
      "cell_type": "code",
      "source": [
        "naive_accs = []\n",
        "\n",
        "for id, task in enumerate(tasks):\n",
        "  avg_acc = 0\n",
        "  print(\"Training on task: \", id)\n",
        "  \n",
        "  (x_train, t_train), _ = task\n",
        "  \n",
        "  for epoch in range(1, 2):\n",
        "    train(model, device, x_train, t_train, optimizer, epoch)\n",
        "    \n",
        "  for id_test, task in enumerate(tasks):\n",
        "    print(\"Testing on task: \", id_test)\n",
        "    _, (x_test, t_test) = task\n",
        "    acc = test(model, device, x_test, t_test)\n",
        "    avg_acc = avg_acc + acc \n",
        "  \n",
        "  naive_accs.append(avg_acc / 3)\n",
        "  print(\"Avg acc: \", avg_acc / 3)\n",
        "  "
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training on task:  0\n",
            "Train Epoch: 1 \tLoss: 0.754318\n",
            "Testing on task:  0\n",
            "Test set: Average loss: 0.0002, Accuracy: 9091/10000 (91%)\n",
            "\n",
            "Testing on task:  1\n",
            "Test set: Average loss: 0.0019, Accuracy: 620/10000 (6%)\n",
            "\n",
            "Testing on task:  2\n",
            "Test set: Average loss: 0.0017, Accuracy: 1229/10000 (12%)\n",
            "\n",
            "Avg acc:  36.46666666666667\n",
            "Training on task:  1\n",
            "Train Epoch: 1 \tLoss: 1.834168\n",
            "Testing on task:  0\n",
            "Test set: Average loss: 0.0028, Accuracy: 1748/10000 (17%)\n",
            "\n",
            "Testing on task:  1\n",
            "Test set: Average loss: 0.0008, Accuracy: 6470/10000 (65%)\n",
            "\n",
            "Testing on task:  2\n",
            "Test set: Average loss: 0.0017, Accuracy: 1288/10000 (13%)\n",
            "\n",
            "Avg acc:  31.686666666666667\n",
            "Training on task:  2\n",
            "Train Epoch: 1 \tLoss: 1.673319\n",
            "Testing on task:  0\n",
            "Test set: Average loss: 0.0046, Accuracy: 1454/10000 (15%)\n",
            "\n",
            "Testing on task:  1\n",
            "Test set: Average loss: 0.0013, Accuracy: 3398/10000 (34%)\n",
            "\n",
            "Testing on task:  2\n",
            "Test set: Average loss: 0.0007, Accuracy: 7139/10000 (71%)\n",
            "\n",
            "Avg acc:  39.97\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ANJfdFD3s0oT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Questions to explore:**\n",
        "\n",
        "*   Does the order of the tasks effect the final results? \n",
        "\n",
        "Some tips here: http://proceedings.mlr.press/v78/lomonaco17a/lomonaco17a.pdf"
      ]
    },
    {
      "metadata": {
        "id": "lCK0EYT-pJa8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Reheasal Strategy\n",
        "\n",
        "Another simple CL idea is to carry on *all* or *part* of the previously encountered examples (of the previous tasks), shuffling them with the data of the current task. Using *all* the past data is near to the optimal performance we can desire at the end of the task sequence but at the expense of much bigger memory usage.\n",
        "\n",
        "Let's start by defining a function to shuffle our data:\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "FdWpT2jhfu3o",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def shuffle_in_unison(dataset, seed, in_place=False):\n",
        "    \"\"\" Shuffle two (or more) list in unison. \"\"\"\n",
        "\n",
        "    np.random.seed(seed)\n",
        "    rng_state = np.random.get_state()\n",
        "    new_dataset = []\n",
        "    for x in dataset:\n",
        "        if in_place:\n",
        "            np.random.shuffle(x)\n",
        "        else:\n",
        "            new_dataset.append(np.random.permutation(x))\n",
        "        np.random.set_state(rng_state)\n",
        "\n",
        "    if not in_place:\n",
        "        return new_dataset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "94hg1UrtqFmT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Now we can reset the model and optimizer and run our training over the tasks sequence:"
      ]
    },
    {
      "metadata": {
        "id": "62TY0Ajgbsgk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = Net().to(device)\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "y_No-qvDbuZi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 665
        },
        "outputId": "167369c1-a89a-4d0f-b2ab-4884361ec09f"
      },
      "cell_type": "code",
      "source": [
        "rehe_accs = []\n",
        "for id, task in enumerate(tasks):\n",
        "  avg_acc = 0\n",
        "  print(\"Training on task: \", id)\n",
        "  \n",
        "  (x_train, t_train), _ = task\n",
        "  \n",
        "  # for previous task\n",
        "  for i in range(id):\n",
        "    (past_x_train, past_t_train), _ = tasks[i]\n",
        "    x_train = np.concatenate((x_train, past_x_train))\n",
        "    t_train = np.concatenate((t_train, past_t_train))\n",
        "  \n",
        "  x_train, t_train = shuffle_in_unison([x_train, t_train], 0)\n",
        "  \n",
        "  for epoch in range(1, 2):\n",
        "    train(model, device, x_train, t_train, optimizer, epoch)\n",
        "    \n",
        "  for id_test, task in enumerate(tasks):\n",
        "    print(\"Testing on task: \", id_test)\n",
        "    _, (x_test, t_test) = task\n",
        "    acc = test(model, device, x_test, t_test)\n",
        "    avg_acc = avg_acc + acc\n",
        "   \n",
        "  print(\"Avg acc: \", avg_acc / 3)\n",
        "  rehe_accs.append(avg_acc/3)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training on task:  0\n",
            "Train Epoch: 1 \tLoss: 0.563346\n",
            "Testing on task:  0\n",
            "Test set: Average loss: 0.0002, Accuracy: 9044/10000 (90%)\n",
            "\n",
            "Testing on task:  1\n",
            "Test set: Average loss: 0.0019, Accuracy: 547/10000 (5%)\n",
            "\n",
            "Testing on task:  2\n",
            "Test set: Average loss: 0.0017, Accuracy: 1023/10000 (10%)\n",
            "\n",
            "Avg acc:  35.38\n",
            "Training on task:  1\n",
            "Train Epoch: 1 \tLoss: 0.744667\n",
            "Testing on task:  0\n",
            "Test set: Average loss: 0.0001, Accuracy: 9397/10000 (94%)\n",
            "\n",
            "Testing on task:  1\n",
            "Test set: Average loss: 0.0003, Accuracy: 7436/10000 (74%)\n",
            "\n",
            "Testing on task:  2\n",
            "Test set: Average loss: 0.0009, Accuracy: 1024/10000 (10%)\n",
            "\n",
            "Avg acc:  59.52333333333333\n",
            "Training on task:  2\n",
            "Train Epoch: 1 \tLoss: 0.724188\n",
            "Testing on task:  0\n",
            "Test set: Average loss: 0.0000, Accuracy: 9498/10000 (95%)\n",
            "\n",
            "Testing on task:  1\n",
            "Test set: Average loss: 0.0001, Accuracy: 8420/10000 (84%)\n",
            "\n",
            "Testing on task:  2\n",
            "Test set: Average loss: 0.0001, Accuracy: 8191/10000 (82%)\n",
            "\n",
            "Avg acc:  87.03000000000002\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "jCna5k0DtN-X",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Questions to explore:**\n",
        "\n",
        "*   Can you find a way to reduce the number of examples of the previous tasks to maintain in memory? \n",
        "*   Can you find a good trade-off between memory overhead and final accuracy?\n",
        "*   Why is shuffling needed here?\n",
        "\n",
        "Some tips here: https://arxiv.org/abs/1809.05922"
      ]
    },
    {
      "metadata": {
        "id": "AqofPHt01Zog",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Elastic Weights Consolidation (EWC) Strategy\n",
        "\n",
        "Elastic Weights Consolidation (EWC) is a common CL strategy firstly proposed in the paper: \"[Overcoming catastrophic forgetting in neural networks](https://arxiv.org/abs/1612.00796)\" for deep neural networks.\n",
        "\n",
        "It is based on the computation of the importance of each weight (fisher information) and a squared regularization loss, penalizing changes in the most important wheights for the previous tasks.\n",
        "\n",
        "It has the great advantage of **not using any** of the previous tasks data!"
      ]
    },
    {
      "metadata": {
        "id": "e9iry5W56xtO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "fisher_dict = {}\n",
        "optpar_dict = {}\n",
        "ewc_lambda = 0.4"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0ZlyqcICEps_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = Net().to(device)\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Clm_QFF12mO9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Now we need to define an additional function to compute the fisher information for each weight at the end of each task:"
      ]
    },
    {
      "metadata": {
        "id": "iEmBNkaO1Ykq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def on_task_update(task_id, x_mem, t_mem):\n",
        "\n",
        "  model.train()\n",
        "  optimizer.zero_grad()\n",
        "  \n",
        "  # accumulating gradients\n",
        "  for start in range(0, len(t_mem)-1, 256):\n",
        "      end = start + 256\n",
        "      x, y = torch.from_numpy(x_mem[start:end]), torch.from_numpy(t_mem[start:end]).long()\n",
        "      x, y = x.to(device), y.to(device)\n",
        "      output = model(x)\n",
        "      loss = F.cross_entropy(output, y)\n",
        "      loss.backward()\n",
        "\n",
        "  fisher_dict[task_id] = {}\n",
        "  optpar_dict[task_id] = {}\n",
        "\n",
        "  # gradients accumulated can be used to calculate fisher\n",
        "  for name, param in model.named_parameters():\n",
        "    \n",
        "    optpar_dict[task_id][name] = param.data.clone()\n",
        "    fisher_dict[task_id][name] = param.grad.data.clone().pow(2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2hGp0Qsf2wa-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We need also to modify our *train* function to add the new regularization loss:"
      ]
    },
    {
      "metadata": {
        "id": "IorTFus1Gs5H",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def train_ewc(model, device, task_id, x_train, t_train, optimizer, epoch):\n",
        "    model.train()\n",
        "\n",
        "    for start in range(0, len(t_train)-1, 256):\n",
        "      end = start + 256\n",
        "      x, y = torch.from_numpy(x_train[start:end]), torch.from_numpy(t_train[start:end]).long()\n",
        "      x, y = x.to(device), y.to(device)\n",
        "      \n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      output = model(x)\n",
        "      loss = F.cross_entropy(output, y)\n",
        "      \n",
        "      ### magic here! :-)\n",
        "      for task in range(task_id):\n",
        "        for name, param in model.named_parameters():\n",
        "          fisher = fisher_dict[task][name]\n",
        "          optpar = optpar_dict[task][name]\n",
        "          loss += (fisher * (optpar - param).pow(2)).sum() * ewc_lambda\n",
        "      \n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      #print(loss.item())\n",
        "    print('Train Epoch: {} \\tLoss: {:.6f}'.format(epoch, loss.item()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "u754qi423EEc",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Finally we can run the train over the three tasks sequence of th *Permuted MNIST*:"
      ]
    },
    {
      "metadata": {
        "id": "IkUCo4C6-QpT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 719
        },
        "outputId": "bc47d63d-bbe1-463b-81da-d119fcc38c9d"
      },
      "cell_type": "code",
      "source": [
        "ewc_accs = []\n",
        "for id, task in enumerate(tasks):\n",
        "  avg_acc = 0\n",
        "  print(\"Training on task: \", id)\n",
        "  \n",
        "  (x_train, t_train), _ = task\n",
        "  \n",
        "  for epoch in range(1, 3):\n",
        "    train_ewc(model, device, id, x_train, t_train, optimizer, epoch)\n",
        "  on_task_update(id, x_train, t_train)\n",
        "    \n",
        "  for id_test, task in enumerate(tasks):\n",
        "    print(\"Testing on task: \", id_test)\n",
        "    _, (x_test, t_test) = task\n",
        "    acc = test(model, device, x_test, t_test)\n",
        "    avg_acc = avg_acc + acc\n",
        "   \n",
        "  print(\"Avg acc: \", avg_acc / 3)\n",
        "  ewc_accs.append(avg_acc / 3)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training on task:  0\n",
            "Train Epoch: 1 \tLoss: 0.873736\n",
            "Train Epoch: 2 \tLoss: 0.520341\n",
            "Testing on task:  0\n",
            "Test set: Average loss: 0.0001, Accuracy: 9437/10000 (94%)\n",
            "\n",
            "Testing on task:  1\n",
            "Test set: Average loss: 0.0020, Accuracy: 686/10000 (7%)\n",
            "\n",
            "Testing on task:  2\n",
            "Test set: Average loss: 0.0016, Accuracy: 1165/10000 (12%)\n",
            "\n",
            "Avg acc:  37.62666666666667\n",
            "Training on task:  1\n",
            "Train Epoch: 1 \tLoss: 2.066581\n",
            "Train Epoch: 2 \tLoss: 1.833169\n",
            "Testing on task:  0\n",
            "Test set: Average loss: 0.0012, Accuracy: 5487/10000 (55%)\n",
            "\n",
            "Testing on task:  1\n",
            "Test set: Average loss: 0.0008, Accuracy: 6786/10000 (68%)\n",
            "\n",
            "Testing on task:  2\n",
            "Test set: Average loss: 0.0018, Accuracy: 1022/10000 (10%)\n",
            "\n",
            "Avg acc:  44.31666666666666\n",
            "Training on task:  2\n",
            "Train Epoch: 1 \tLoss: 2.145576\n",
            "Train Epoch: 2 \tLoss: 1.886335\n",
            "Testing on task:  0\n",
            "Test set: Average loss: 0.0014, Accuracy: 6614/10000 (66%)\n",
            "\n",
            "Testing on task:  1\n",
            "Test set: Average loss: 0.0014, Accuracy: 3208/10000 (32%)\n",
            "\n",
            "Testing on task:  2\n",
            "Test set: Average loss: 0.0007, Accuracy: 6940/10000 (69%)\n",
            "\n",
            "Avg acc:  55.873333333333335\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Nx4bR5K1uIwU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Questions to explore:**\n",
        "\n",
        "*   How much the `ewc_lambda` parameter effect the final results? \n",
        "*   Can you find a better parametrization to improve stability?\n",
        "*   Can you find the memory overhead introduced by EWC with respect to the Naive approach?\n",
        "\n",
        "Some tips here: https://arxiv.org/pdf/1805.06370.pdf"
      ]
    },
    {
      "metadata": {
        "id": "o3SM7U5fwTqV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Plot Results\n",
        "\n",
        "To conclude, let's summerize our results in a nice plot! :-)"
      ]
    },
    {
      "metadata": {
        "id": "sIQEVVpDwPP5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 382
        },
        "outputId": "da684b3b-05ea-493f-84e6-fa4295b8827a"
      },
      "cell_type": "code",
      "source": [
        "plt.plot([1, 2, 3], naive_accs, '-o', label=\"Naive\")\n",
        "plt.plot([1, 2, 3], rehe_accs, '-o', label=\"Rehearsal\")\n",
        "plt.plot([1, 2, 3], ewc_accs, '-o', label=\"EWC\")\n",
        "plt.xlabel('Tasks Encountered', fontsize=14)\n",
        "plt.ylabel('Average Accuracy', fontsize=14)\n",
        "plt.title('CL Strategies Comparison on MNSIT', fontsize=14);\n",
        "plt.xticks([1, 2, 3])\n",
        "plt.legend(prop={'size': 16});"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfEAAAFtCAYAAAAXllNFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n6ApIfQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f6f91b6d780>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "9x1D3O7iunxS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Questions to explore:**\n",
        "\n",
        "*   What's the difference in terms of memory utilization among the three methods? \n",
        "*   Can you plot a similar graph highlighting the memory increase over time?\n",
        "\n",
        "Some tips here: https://stackoverflow.com/questions/449560/how-do-i-determine-the-size-of-an-object-in-python/30316760"
      ]
    },
    {
      "metadata": {
        "id": "OS9gHzZM7HQr",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Copyright (c) 2018. Continual AI. All rights reserved. **\n",
        "\n",
        "See the accompanying LICENSE file in the GitHub repository for terms. \n",
        "\n",
        "*Date: 29-09-2018                                                             \n",
        "Author: Vincenzo Lomonaco                                                    \n",
        "E-mail: contact@continualai.org                                           \n",
        "Website: continualai.org*                                               "
      ]
    }
  ]
}