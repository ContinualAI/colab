{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Training\n",
    "\n",
    "First, let's install Avalanche. You can skip this step if you have installed it already."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "!pip install avalanche-lib=0.2.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Benchmarks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "you can import benchmarks from the `avl.benchmarks` module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from avalanche.benchmarks import SplitMNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len train: 5, len test: 5\n"
     ]
    }
   ],
   "source": [
    "benchmark = SplitMNIST(\n",
    "    n_experiences=5,\n",
    "    return_task_id=False\n",
    ")\n",
    "train_stream = benchmark.train_stream\n",
    "test_stream = benchmark.test_stream\n",
    "\n",
    "print(f\"len train: {len(train_stream)}, len test: {len(test_stream)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0) - T0, classes=[3, 7]\n",
      "(1) - T0, classes=[4, 6]\n",
      "(2) - T0, classes=[0, 5]\n",
      "(3) - T0, classes=[8, 2]\n",
      "(4) - T0, classes=[1, 9]\n"
     ]
    }
   ],
   "source": [
    "for exp in train_stream:\n",
    "    eid = exp.current_experience\n",
    "    curr_classes = exp.classes_in_this_experience\n",
    "    tid = exp.task_label\n",
    "    print(f\"({eid}) - T{tid}, classes={curr_classes}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " now let's try with a multi-task benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len train: 5, len test: 5\n"
     ]
    }
   ],
   "source": [
    "benchmark = SplitMNIST(\n",
    "    n_experiences=5,\n",
    "    return_task_id=True\n",
    ")\n",
    "train_stream = benchmark.train_stream\n",
    "test_stream = benchmark.test_stream\n",
    "\n",
    "print(f\"len train: {len(train_stream)}, len test: {len(test_stream)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0) - T0, classes=[0, 1]\n",
      "(1) - T1, classes=[0, 1]\n",
      "(2) - T2, classes=[0, 1]\n",
      "(3) - T3, classes=[0, 1]\n",
      "(4) - T4, classes=[0, 1]\n"
     ]
    }
   ],
   "source": [
    "for exp in train_stream:\n",
    "    eid = exp.current_experience\n",
    "    curr_classes = exp.classes_in_this_experience\n",
    "    tid = exp.task_label\n",
    "    print(f\"({eid}) - T{tid}, classes={curr_classes}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-Task Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "you can use pytorch models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP(\n",
      "  (features): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "  )\n",
      "  (classifier): Linear(in_features=512, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Linear(784, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.classifier = nn.Linear(512, 10)\n",
    "    \n",
    "    def forward(self, x, **kwargs):\n",
    "        x = x.reshape(x.shape[0], -1)\n",
    "        x = self.features(x)\n",
    "        return self.classifier(x)\n",
    "    \n",
    "model = MLP()\n",
    "model(torch.randn(32, 784))\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MLP is ignoring task_labels. You can use Avalanche MultiHeadClassifier to split the output layer by task id."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-5.2818e-02, -1.1711e-01, -4.0755e-02,  6.2580e-02, -2.7195e-02,\n",
       "          1.6112e-01,  8.8212e-02,  5.4748e-02,  1.1080e-01, -1.1024e-01],\n",
       "        [-4.8843e-02, -6.7356e-02,  9.0853e-02,  8.9037e-02,  4.0431e-02,\n",
       "          9.2167e-02,  5.9377e-02, -4.3629e-02,  6.8562e-02, -1.4341e-01],\n",
       "        [-1.0278e-01, -5.2737e-03,  7.3208e-02,  2.5740e-02, -5.0809e-02,\n",
       "          1.0314e-01,  6.2482e-02,  4.6415e-02, -2.7389e-02,  1.1042e-02],\n",
       "        [-5.0386e-02, -8.8294e-02,  3.5914e-03, -5.0179e-02, -1.0267e-01,\n",
       "          7.3686e-02,  2.9858e-04,  5.6256e-03, -3.8574e-03, -5.6767e-02],\n",
       "        [ 2.0078e-01, -1.4191e-01,  4.9989e-02,  1.3214e-02, -2.4189e-04,\n",
       "         -4.0756e-03,  8.3634e-02, -9.3482e-02,  1.7649e-02, -8.6874e-02],\n",
       "        [-7.5609e-02,  1.2334e-02, -1.2911e-02, -4.7168e-03,  4.7949e-02,\n",
       "          1.2498e-01,  8.0643e-02,  3.9433e-02,  5.1224e-02, -8.4854e-02],\n",
       "        [ 1.9634e-02, -3.1073e-02,  1.3481e-01,  3.3806e-02,  2.6018e-02,\n",
       "         -9.8696e-04,  5.1616e-02, -1.7968e-02,  7.8726e-02,  3.5757e-02],\n",
       "        [ 9.0526e-02, -5.3515e-02,  9.9869e-02, -2.2818e-02,  7.7563e-03,\n",
       "         -6.3922e-02,  1.8707e-01, -5.5956e-02, -6.4179e-02, -4.4347e-02],\n",
       "        [-1.5038e-01, -3.7025e-02, -9.9341e-02,  1.1596e-01,  5.6693e-02,\n",
       "          4.5168e-02,  1.6632e-01, -1.7040e-02,  5.4339e-02, -1.2893e-01],\n",
       "        [-5.2483e-02, -8.2500e-02, -4.4369e-02,  4.3220e-02, -9.4194e-03,\n",
       "         -8.5865e-02,  1.3163e-01,  5.5786e-02, -3.2372e-02, -1.7560e-01],\n",
       "        [-1.1671e-02, -1.1171e-01,  1.0368e-01,  1.4561e-01,  8.4181e-02,\n",
       "          8.5636e-03,  1.5425e-01,  1.3065e-01, -3.9565e-02, -5.7654e-02],\n",
       "        [ 2.3265e-02, -1.2109e-01, -4.5095e-02, -6.0141e-02, -9.8494e-02,\n",
       "          1.6581e-01,  9.8642e-02, -2.4840e-04,  1.6510e-01, -1.2497e-01],\n",
       "        [ 2.0428e-02, -6.9168e-02,  5.8886e-02, -7.6310e-02, -8.4156e-02,\n",
       "          6.6756e-02,  1.9295e-01,  1.2137e-02,  1.3662e-01, -1.1846e-01],\n",
       "        [-1.5023e-01,  2.5066e-02, -2.0412e-02,  5.5006e-02,  4.1125e-02,\n",
       "          1.5641e-01,  1.0989e-01, -8.5689e-02, -1.6664e-02,  4.4638e-02],\n",
       "        [ 9.5297e-02, -1.4311e-01,  3.4689e-03, -1.2952e-01,  7.9156e-02,\n",
       "         -1.6042e-02,  6.8633e-02, -3.4450e-02,  8.7076e-02, -7.3812e-02],\n",
       "        [ 3.8762e-02, -9.1645e-02, -2.8717e-02,  3.8914e-02, -9.1736e-03,\n",
       "          7.1070e-02,  1.2545e-01,  3.3174e-02, -1.6662e-02, -9.3959e-02],\n",
       "        [ 9.2596e-02, -1.3454e-01,  1.9704e-02, -5.1273e-02, -3.6741e-02,\n",
       "          5.0038e-02,  3.1757e-02,  2.9483e-02,  1.4406e-01, -1.5400e-01],\n",
       "        [ 6.0049e-02, -8.4124e-02,  1.6153e-02, -1.2026e-02,  1.2775e-01,\n",
       "         -9.9357e-03,  2.3567e-01, -8.1968e-02,  8.7776e-02,  2.3443e-02],\n",
       "        [-3.2688e-03, -4.5658e-02,  3.6357e-02,  1.2705e-02, -1.8675e-01,\n",
       "          1.2239e-01,  1.0472e-01, -3.9651e-03,  9.1030e-03, -1.9508e-02],\n",
       "        [-2.8108e-03, -1.2382e-01,  5.4474e-02,  3.7393e-02,  4.2942e-02,\n",
       "         -6.3883e-02,  1.0664e-01, -1.5803e-02,  1.7819e-01,  6.0082e-02],\n",
       "        [-6.9891e-02, -4.7464e-02,  7.8576e-02, -9.9126e-02, -3.9053e-02,\n",
       "         -2.1778e-02,  1.0665e-01,  2.2731e-02,  1.5820e-01, -3.1421e-02],\n",
       "        [-2.7493e-02, -7.0808e-02, -3.2016e-02,  3.1716e-02, -1.0478e-01,\n",
       "          8.8578e-02, -3.3613e-02, -2.4954e-02,  1.6072e-01, -3.1750e-02],\n",
       "        [ 5.8682e-02, -9.7047e-02,  6.1433e-02, -1.5922e-02, -2.6212e-02,\n",
       "          7.8807e-02,  5.2988e-02,  3.7614e-02,  9.6881e-02, -1.5769e-03],\n",
       "        [ 9.1622e-02, -1.2836e-01,  2.7146e-03, -6.3755e-02,  4.8812e-02,\n",
       "          6.1853e-03,  1.8985e-01, -5.7378e-02,  1.1354e-01,  1.4461e-02],\n",
       "        [-4.3873e-02, -2.6845e-02, -3.6231e-02,  3.5572e-03,  8.1964e-03,\n",
       "          5.8086e-02,  8.6350e-02, -1.6831e-02,  3.8684e-02, -5.4741e-02],\n",
       "        [-2.0907e-02, -7.6887e-02,  7.1523e-02, -7.8112e-02,  4.0411e-02,\n",
       "          6.7196e-02,  2.0465e-01, -5.5568e-02,  1.0240e-01, -1.0843e-01],\n",
       "        [-9.8301e-02, -5.8606e-02,  9.9446e-03, -4.7608e-02,  3.2055e-02,\n",
       "          3.3498e-02,  7.7573e-02,  2.2143e-03,  6.9947e-03,  4.7057e-03],\n",
       "        [-5.6566e-02, -1.8143e-02,  3.0365e-02, -3.4909e-02,  7.2870e-02,\n",
       "          7.2397e-03,  1.5163e-01, -3.5241e-02,  1.0210e-01, -6.8784e-03],\n",
       "        [-4.3662e-02, -7.5342e-02, -1.9483e-02,  6.7753e-02,  1.0904e-01,\n",
       "         -8.8149e-02,  9.5042e-02,  4.3465e-03,  1.6939e-02, -1.2824e-01],\n",
       "        [-1.4365e-01, -1.2006e-01,  1.5359e-02, -5.6458e-02,  3.0491e-02,\n",
       "         -3.8592e-02,  2.6241e-01,  3.9650e-02,  6.8471e-02,  6.7313e-02],\n",
       "        [-9.2765e-02, -5.5185e-02,  5.5447e-02, -9.0280e-02, -1.1095e-01,\n",
       "          5.4455e-02,  8.8587e-02, -6.0619e-02,  5.9510e-02, -1.5015e-01],\n",
       "        [-4.8956e-02, -6.2992e-02,  6.7324e-02, -9.7479e-02,  9.0981e-03,\n",
       "         -6.0006e-02,  1.0510e-01, -5.8969e-02,  3.0290e-02, -3.6652e-02]],\n",
       "       grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(32, 784)\n",
    "t = torch.randint(low=0, high=4, size=(32,))\n",
    "model(x, task_labels=t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultiTaskDecorator(\n",
      "  (model): MLP(\n",
      "    (features): Sequential(\n",
      "      (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "      (3): ReLU()\n",
      "    )\n",
      "    (classifier): Sequential()\n",
      "  )\n",
      "  (classifier): MultiHeadClassifier(\n",
      "    (classifiers): ModuleDict(\n",
      "      (0): IncrementalClassifier(\n",
      "        (classifier): Linear(in_features=512, out_features=10, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from avalanche.models import as_multitask\n",
    "\n",
    "model_mt = as_multitask(MLP(), 'classifier')\n",
    "print(model_mt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model still doesn't know about all the tasks because it has neven seen them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'1'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[1;32mIn [27]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmodel_mt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask_labels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\avl_02\\lib\\site-packages\\torch\\nn\\modules\\module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\avl_02\\lib\\site-packages\\avalanche\\models\\dynamic_modules.py:162\u001b[0m, in \u001b[0;36mMultiTaskModule.forward\u001b[1;34m(self, x, task_labels)\u001b[0m\n\u001b[0;32m    160\u001b[0m task_mask \u001b[38;5;241m=\u001b[39m task_labels \u001b[38;5;241m==\u001b[39m task\n\u001b[0;32m    161\u001b[0m x_task \u001b[38;5;241m=\u001b[39m x[task_mask]\n\u001b[1;32m--> 162\u001b[0m out_task \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward_single_task\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_task\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    163\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out_task\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m, (\n\u001b[0;32m    164\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulti-head assumes mini-batches of 2 dimensions \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    165\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<batch, classes>\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    166\u001b[0m )\n\u001b[0;32m    167\u001b[0m n_labels_head \u001b[38;5;241m=\u001b[39m out_task\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\avl_02\\lib\\site-packages\\avalanche\\models\\helper_method.py:71\u001b[0m, in \u001b[0;36mMultiTaskDecorator.forward_single_task\u001b[1;34m(self, x, task_label)\u001b[0m\n\u001b[0;32m     69\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward_single_task\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: torch\u001b[38;5;241m.\u001b[39mTensor, task_label: \u001b[38;5;28mint\u001b[39m):\n\u001b[0;32m     70\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel(x)\n\u001b[1;32m---> 71\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclassifier_name\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     72\u001b[0m \u001b[43m        \u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask_labels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtask_label\u001b[49m\n\u001b[0;32m     73\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\avl_02\\lib\\site-packages\\torch\\nn\\modules\\module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\avl_02\\lib\\site-packages\\avalanche\\models\\dynamic_modules.py:154\u001b[0m, in \u001b[0;36mMultiTaskModule.forward\u001b[1;34m(self, x, task_labels)\u001b[0m\n\u001b[0;32m    150\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforward_all_tasks(x)\n\u001b[0;32m    152\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(task_labels, \u001b[38;5;28mint\u001b[39m):\n\u001b[0;32m    153\u001b[0m     \u001b[38;5;66;03m# fast path. mini-batch is single task.\u001b[39;00m\n\u001b[1;32m--> 154\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward_single_task\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask_labels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    155\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    156\u001b[0m     unique_tasks \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39munique(task_labels)\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\avl_02\\lib\\site-packages\\avalanche\\models\\dynamic_modules.py:386\u001b[0m, in \u001b[0;36mMultiHeadClassifier.forward_single_task\u001b[1;34m(self, x, task_label)\u001b[0m\n\u001b[0;32m    378\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward_single_task\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, task_label):\n\u001b[0;32m    379\u001b[0m     \u001b[38;5;124;03m\"\"\"compute the output given the input `x`. This module uses the task\u001b[39;00m\n\u001b[0;32m    380\u001b[0m \u001b[38;5;124;03m    label to activate the correct head.\u001b[39;00m\n\u001b[0;32m    381\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    384\u001b[0m \u001b[38;5;124;03m    :return:\u001b[39;00m\n\u001b[0;32m    385\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 386\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclassifiers\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtask_label\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m(x)\n\u001b[0;32m    387\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmasking:\n\u001b[0;32m    388\u001b[0m         au_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mactive_units_T\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtask_label\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\avl_02\\lib\\site-packages\\torch\\nn\\modules\\container.py:328\u001b[0m, in \u001b[0;36mModuleDict.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    326\u001b[0m \u001b[38;5;129m@_copy_to_script_wrapper\u001b[39m\n\u001b[0;32m    327\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, key: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Module:\n\u001b[1;32m--> 328\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_modules\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\n",
      "\u001b[1;31mKeyError\u001b[0m: '1'"
     ]
    }
   ],
   "source": [
    "model_mt(x, task_labels=t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You have to adapt the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultiTaskDecorator(\n",
      "  (model): MLP(\n",
      "    (features): Sequential(\n",
      "      (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "      (3): ReLU()\n",
      "    )\n",
      "    (classifier): Sequential()\n",
      "  )\n",
      "  (classifier): MultiHeadClassifier(\n",
      "    (classifiers): ModuleDict(\n",
      "      (0): IncrementalClassifier(\n",
      "        (classifier): Linear(in_features=512, out_features=10, bias=True)\n",
      "      )\n",
      "      (1): IncrementalClassifier(\n",
      "        (classifier): Linear(in_features=512, out_features=10, bias=True)\n",
      "      )\n",
      "      (2): IncrementalClassifier(\n",
      "        (classifier): Linear(in_features=512, out_features=10, bias=True)\n",
      "      )\n",
      "      (3): IncrementalClassifier(\n",
      "        (classifier): Linear(in_features=512, out_features=10, bias=True)\n",
      "      )\n",
      "      (4): IncrementalClassifier(\n",
      "        (classifier): Linear(in_features=512, out_features=10, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from avalanche.models import DynamicModule\n",
    "\n",
    "for exp in benchmark.train_stream:\n",
    "    for m in model_mt.modules():\n",
    "        if isinstance(m, DynamicModule):\n",
    "            m.adaptation(exp)\n",
    "\n",
    "print(model_mt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the model has been adapted to all the tasks. A separate head for each task is available for classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.1171e-02, -9.0120e-02, -1.0000e+03, -1.0000e+03, -1.0000e+03,\n",
       "         -1.0000e+03, -1.0000e+03, -1.0000e+03, -1.0000e+03, -1.0000e+03],\n",
       "        [-9.5024e-02, -4.7357e-02, -1.0000e+03, -1.0000e+03, -1.0000e+03,\n",
       "         -1.0000e+03, -1.0000e+03, -1.0000e+03, -1.0000e+03, -1.0000e+03],\n",
       "        [-9.1795e-02,  1.4599e-02, -1.0000e+03, -1.0000e+03, -1.0000e+03,\n",
       "         -1.0000e+03, -1.0000e+03, -1.0000e+03, -1.0000e+03, -1.0000e+03],\n",
       "        [-4.4824e-02,  8.8849e-03, -1.0000e+03, -1.0000e+03, -1.0000e+03,\n",
       "         -1.0000e+03, -1.0000e+03, -1.0000e+03, -1.0000e+03, -1.0000e+03],\n",
       "        [-1.4652e-02, -8.7687e-02, -1.0000e+03, -1.0000e+03, -1.0000e+03,\n",
       "         -1.0000e+03, -1.0000e+03, -1.0000e+03, -1.0000e+03, -1.0000e+03],\n",
       "        [-5.0053e-02, -1.0758e-01, -1.0000e+03, -1.0000e+03, -1.0000e+03,\n",
       "         -1.0000e+03, -1.0000e+03, -1.0000e+03, -1.0000e+03, -1.0000e+03],\n",
       "        [ 4.0553e-02,  1.9057e-01, -1.0000e+03, -1.0000e+03, -1.0000e+03,\n",
       "         -1.0000e+03, -1.0000e+03, -1.0000e+03, -1.0000e+03, -1.0000e+03],\n",
       "        [-8.8071e-02,  1.9716e-02, -1.0000e+03, -1.0000e+03, -1.0000e+03,\n",
       "         -1.0000e+03, -1.0000e+03, -1.0000e+03, -1.0000e+03, -1.0000e+03],\n",
       "        [-4.5827e-02, -6.0859e-02, -1.0000e+03, -1.0000e+03, -1.0000e+03,\n",
       "         -1.0000e+03, -1.0000e+03, -1.0000e+03, -1.0000e+03, -1.0000e+03],\n",
       "        [ 4.9985e-02,  1.9627e-02, -1.0000e+03, -1.0000e+03, -1.0000e+03,\n",
       "         -1.0000e+03, -1.0000e+03, -1.0000e+03, -1.0000e+03, -1.0000e+03],\n",
       "        [ 1.0424e-01, -2.5693e-02, -1.0000e+03, -1.0000e+03, -1.0000e+03,\n",
       "         -1.0000e+03, -1.0000e+03, -1.0000e+03, -1.0000e+03, -1.0000e+03],\n",
       "        [ 2.0560e-03,  1.4516e-02, -1.0000e+03, -1.0000e+03, -1.0000e+03,\n",
       "         -1.0000e+03, -1.0000e+03, -1.0000e+03, -1.0000e+03, -1.0000e+03],\n",
       "        [-5.1105e-02, -2.9382e-02, -1.0000e+03, -1.0000e+03, -1.0000e+03,\n",
       "         -1.0000e+03, -1.0000e+03, -1.0000e+03, -1.0000e+03, -1.0000e+03],\n",
       "        [ 9.2519e-02, -1.3789e-01, -1.0000e+03, -1.0000e+03, -1.0000e+03,\n",
       "         -1.0000e+03, -1.0000e+03, -1.0000e+03, -1.0000e+03, -1.0000e+03],\n",
       "        [-6.3986e-02, -1.5545e-02, -1.0000e+03, -1.0000e+03, -1.0000e+03,\n",
       "         -1.0000e+03, -1.0000e+03, -1.0000e+03, -1.0000e+03, -1.0000e+03],\n",
       "        [ 4.7073e-02, -9.8461e-02, -1.0000e+03, -1.0000e+03, -1.0000e+03,\n",
       "         -1.0000e+03, -1.0000e+03, -1.0000e+03, -1.0000e+03, -1.0000e+03],\n",
       "        [ 1.5950e-02, -3.4311e-02, -1.0000e+03, -1.0000e+03, -1.0000e+03,\n",
       "         -1.0000e+03, -1.0000e+03, -1.0000e+03, -1.0000e+03, -1.0000e+03],\n",
       "        [ 6.6323e-02,  6.9443e-02, -1.0000e+03, -1.0000e+03, -1.0000e+03,\n",
       "         -1.0000e+03, -1.0000e+03, -1.0000e+03, -1.0000e+03, -1.0000e+03],\n",
       "        [ 8.4089e-02,  4.6718e-02, -1.0000e+03, -1.0000e+03, -1.0000e+03,\n",
       "         -1.0000e+03, -1.0000e+03, -1.0000e+03, -1.0000e+03, -1.0000e+03],\n",
       "        [-1.0408e-01,  5.1131e-02, -1.0000e+03, -1.0000e+03, -1.0000e+03,\n",
       "         -1.0000e+03, -1.0000e+03, -1.0000e+03, -1.0000e+03, -1.0000e+03],\n",
       "        [ 4.8543e-02,  4.6063e-02, -1.0000e+03, -1.0000e+03, -1.0000e+03,\n",
       "         -1.0000e+03, -1.0000e+03, -1.0000e+03, -1.0000e+03, -1.0000e+03],\n",
       "        [-1.3925e-01,  2.4244e-01, -1.0000e+03, -1.0000e+03, -1.0000e+03,\n",
       "         -1.0000e+03, -1.0000e+03, -1.0000e+03, -1.0000e+03, -1.0000e+03],\n",
       "        [-6.5670e-02,  1.1684e-01, -1.0000e+03, -1.0000e+03, -1.0000e+03,\n",
       "         -1.0000e+03, -1.0000e+03, -1.0000e+03, -1.0000e+03, -1.0000e+03],\n",
       "        [ 3.7032e-03, -3.5538e-03, -1.0000e+03, -1.0000e+03, -1.0000e+03,\n",
       "         -1.0000e+03, -1.0000e+03, -1.0000e+03, -1.0000e+03, -1.0000e+03],\n",
       "        [ 4.6856e-02,  6.0776e-02, -1.0000e+03, -1.0000e+03, -1.0000e+03,\n",
       "         -1.0000e+03, -1.0000e+03, -1.0000e+03, -1.0000e+03, -1.0000e+03],\n",
       "        [ 8.4658e-02,  1.5309e-01, -1.0000e+03, -1.0000e+03, -1.0000e+03,\n",
       "         -1.0000e+03, -1.0000e+03, -1.0000e+03, -1.0000e+03, -1.0000e+03],\n",
       "        [-2.9397e-02,  3.7793e-03, -1.0000e+03, -1.0000e+03, -1.0000e+03,\n",
       "         -1.0000e+03, -1.0000e+03, -1.0000e+03, -1.0000e+03, -1.0000e+03],\n",
       "        [ 3.7183e-02,  1.9744e-02, -1.0000e+03, -1.0000e+03, -1.0000e+03,\n",
       "         -1.0000e+03, -1.0000e+03, -1.0000e+03, -1.0000e+03, -1.0000e+03],\n",
       "        [ 1.0507e-01,  3.5373e-02, -1.0000e+03, -1.0000e+03, -1.0000e+03,\n",
       "         -1.0000e+03, -1.0000e+03, -1.0000e+03, -1.0000e+03, -1.0000e+03],\n",
       "        [-1.2414e-02,  7.4455e-03, -1.0000e+03, -1.0000e+03, -1.0000e+03,\n",
       "         -1.0000e+03, -1.0000e+03, -1.0000e+03, -1.0000e+03, -1.0000e+03],\n",
       "        [-4.9343e-03,  1.7135e-02, -1.0000e+03, -1.0000e+03, -1.0000e+03,\n",
       "         -1.0000e+03, -1.0000e+03, -1.0000e+03, -1.0000e+03, -1.0000e+03],\n",
       "        [ 3.8454e-02, -2.7565e-03, -1.0000e+03, -1.0000e+03, -1.0000e+03,\n",
       "         -1.0000e+03, -1.0000e+03, -1.0000e+03, -1.0000e+03, -1.0000e+03]],\n",
       "       grad_fn=<IndexPutBackward0>)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_mt(x, task_labels=t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Training\n",
    "\n",
    "Each strategy object offers two main methods: `train` and `eval`. Both of them, accept either a _single experience_(`Experience`) or a _list of them_, for maximum flexibility.\n",
    "\n",
    "We can train the model continually by iterating over the `train_stream` provided by the scenario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from torch.optim import SGD\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from avalanche.models import SimpleMLP\n",
    "from avalanche.training import Naive\n",
    "\n",
    "# scenario\n",
    "benchmark = SplitMNIST(\n",
    "    n_experiences=5,\n",
    "    return_task_id=True,\n",
    "    seed=1\n",
    ")\n",
    "\n",
    "# model\n",
    "model = as_multitask(MLP(), 'classifier')\n",
    "optimizer = SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "criterion = CrossEntropyLoss()\n",
    "\n",
    "# strategy\n",
    "cl_strategy = Naive(\n",
    "    model=model, \n",
    "    optimizer=optimizer, \n",
    "    criterion=criterion,\n",
    "    train_mb_size=100, \n",
    "    train_epochs=1, \n",
    "    eval_mb_size=100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- >> Start of training phase << --\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 114/114 [00:04<00:00, 24.26it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.3752\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.8766\n",
      "-- >> End of training phase << --\n",
      "-- >> Start of training phase << --\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 127/127 [00:05<00:00, 24.36it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task001 = 0.2639\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task001 = 0.9317\n",
      "-- >> End of training phase << --\n",
      "-- >> Start of training phase << --\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 118/118 [00:04<00:00, 24.47it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task002 = 0.2196\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task002 = 0.9381\n",
      "-- >> End of training phase << --\n",
      "-- >> Start of training phase << --\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 121/121 [00:04<00:00, 24.71it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task003 = 0.2765\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task003 = 0.9189\n",
      "-- >> End of training phase << --\n",
      "-- >> Start of training phase << --\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 122/122 [00:05<00:00, 24.39it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task004 = 0.2735\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task004 = 0.9092\n",
      "-- >> End of training phase << --\n",
      "-- >> Start of eval phase << --\n",
      "-- Starting eval on experience 0 (Task 0) from test stream --\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 19/19 [00:00<00:00, 29.25it/s]\n",
      "> Eval on experience 0 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp000 = 0.1502\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.9470\n",
      "-- Starting eval on experience 1 (Task 1) from test stream --\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 22/22 [00:00<00:00, 28.23it/s]\n",
      "> Eval on experience 1 (Task 1) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task001/Exp001 = 0.0808\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task001/Exp001 = 0.9709\n",
      "-- Starting eval on experience 2 (Task 2) from test stream --\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 20/20 [00:00<00:00, 27.85it/s]\n",
      "> Eval on experience 2 (Task 2) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task002/Exp002 = 0.0835\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task002/Exp002 = 0.9719\n",
      "-- Starting eval on experience 3 (Task 3) from test stream --\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 21/21 [00:00<00:00, 30.54it/s]\n",
      "> Eval on experience 3 (Task 3) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task003/Exp003 = 0.1101\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task003/Exp003 = 0.9708\n",
      "-- Starting eval on experience 4 (Task 4) from test stream --\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 21/21 [00:00<00:00, 28.46it/s]\n",
      "> Eval on experience 4 (Task 4) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task004/Exp004 = 0.0862\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task004/Exp004 = 0.9771\n",
      "-- >> End of eval phase << --\n",
      "\tLoss_Stream/eval_phase/test_stream/Task000 = 0.1502\n",
      "\tLoss_Stream/eval_phase/test_stream/Task001 = 0.0808\n",
      "\tLoss_Stream/eval_phase/test_stream/Task002 = 0.0835\n",
      "\tLoss_Stream/eval_phase/test_stream/Task003 = 0.1101\n",
      "\tLoss_Stream/eval_phase/test_stream/Task004 = 0.0862\n",
      "\tTop1_Acc_Stream/eval_phase/test_stream/Task000 = 0.9470\n",
      "\tTop1_Acc_Stream/eval_phase/test_stream/Task001 = 0.9709\n",
      "\tTop1_Acc_Stream/eval_phase/test_stream/Task002 = 0.9719\n",
      "\tTop1_Acc_Stream/eval_phase/test_stream/Task003 = 0.9708\n",
      "\tTop1_Acc_Stream/eval_phase/test_stream/Task004 = 0.9771\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Top1_Acc_Epoch/train_phase/train_stream/Task000': 0.8766205132727753,\n",
       " 'Loss_Epoch/train_phase/train_stream/Task000': 0.3752482113228745,\n",
       " 'Top1_Acc_Epoch/train_phase/train_stream/Task001': 0.9317322834645669,\n",
       " 'Loss_Epoch/train_phase/train_stream/Task001': 0.2638802383769685,\n",
       " 'Top1_Acc_Epoch/train_phase/train_stream/Task002': 0.9380839137081706,\n",
       " 'Loss_Epoch/train_phase/train_stream/Task002': 0.2196187972971837,\n",
       " 'Top1_Acc_Epoch/train_phase/train_stream/Task003': 0.9188741721854304,\n",
       " 'Loss_Epoch/train_phase/train_stream/Task003': 0.27645327155755844,\n",
       " 'Top1_Acc_Epoch/train_phase/train_stream/Task004': 0.9092260675642191,\n",
       " 'Loss_Epoch/train_phase/train_stream/Task004': 0.2734750110715716,\n",
       " 'Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp000': 0.947027027027027,\n",
       " 'Loss_Exp/eval_phase/test_stream/Task000/Exp000': 0.15023965730860428,\n",
       " 'Top1_Acc_Exp/eval_phase/test_stream/Task001/Exp001': 0.9709275496077526,\n",
       " 'Loss_Exp/eval_phase/test_stream/Task001/Exp001': 0.08084066453538956,\n",
       " 'Top1_Acc_Exp/eval_phase/test_stream/Task002/Exp002': 0.9718526100307062,\n",
       " 'Loss_Exp/eval_phase/test_stream/Task002/Exp002': 0.08346750995405437,\n",
       " 'Top1_Acc_Exp/eval_phase/test_stream/Task003/Exp003': 0.9707776126795443,\n",
       " 'Loss_Exp/eval_phase/test_stream/Task003/Exp003': 0.11009896243634112,\n",
       " 'Top1_Acc_Exp/eval_phase/test_stream/Task004/Exp004': 0.9771144278606965,\n",
       " 'Loss_Exp/eval_phase/test_stream/Task004/Exp004': 0.08618990087242269,\n",
       " 'Top1_Acc_Stream/eval_phase/test_stream/Task000': 0.947027027027027,\n",
       " 'Top1_Acc_Stream/eval_phase/test_stream/Task001': 0.9709275496077526,\n",
       " 'Top1_Acc_Stream/eval_phase/test_stream/Task002': 0.9718526100307062,\n",
       " 'Top1_Acc_Stream/eval_phase/test_stream/Task003': 0.9707776126795443,\n",
       " 'Top1_Acc_Stream/eval_phase/test_stream/Task004': 0.9771144278606965,\n",
       " 'Loss_Stream/eval_phase/test_stream/Task000': 0.15023965730860428,\n",
       " 'Loss_Stream/eval_phase/test_stream/Task001': 0.08084066453538956,\n",
       " 'Loss_Stream/eval_phase/test_stream/Task002': 0.08346750995405437,\n",
       " 'Loss_Stream/eval_phase/test_stream/Task003': 0.11009896243634112,\n",
       " 'Loss_Stream/eval_phase/test_stream/Task004': 0.08618990087242269}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for exp in benchmark.train_stream:\n",
    "    cl_strategy.train(exp)\n",
    "cl_strategy.eval(benchmark.test_stream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- >> Start of training phase << --\n",
      "-- >> Start of eval phase << --\n",
      "-- Starting eval on experience 0 (Task 0) from train stream --\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\w-32\\Anaconda3\\envs\\avl_02\\lib\\site-packages\\avalanche\\training\\plugins\\evaluation.py:81: UserWarning: No benchmark provided to the evaluation plugin. Metrics may be computed on inconsistent portion of streams, use at your own risk.\n",
      "  warnings.warn(\n",
      "C:\\Users\\w-32\\Anaconda3\\envs\\avl_02\\lib\\site-packages\\avalanche\\training\\plugins\\evaluation.py:228: UserWarning: Evaluation stream is not equal to the complete test stream. This may result in inconsistent metrics. Use at your own risk.\n",
      "  warnings.warn(msgw)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 114/114 [00:03<00:00, 31.59it/s]\n",
      "> Eval on experience 0 (Task 0) from train stream ended.\n",
      "\tTop1_Acc_Exp/eval_phase/train_stream/Task000/Exp000 = 0.4781\n",
      "-- Starting eval on experience 1 (Task 1) from train stream --\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 127/127 [00:04<00:00, 31.45it/s]\n",
      "> Eval on experience 1 (Task 1) from train stream ended.\n",
      "\tTop1_Acc_Exp/eval_phase/train_stream/Task001/Exp001 = 0.5309\n",
      "-- >> End of eval phase << --\n",
      "\tTop1_Acc_Stream/eval_phase/train_stream/Task000 = 0.4781\n",
      "\tTop1_Acc_Stream/eval_phase/train_stream/Task001 = 0.5309\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 114/114 [00:04<00:00, 26.49it/s]\n",
      "Epoch 0 ended.\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9016\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 1.0000\n",
      "-- >> Start of eval phase << --\n",
      "-- Starting eval on experience 0 (Task 0) from train stream --\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 114/114 [00:03<00:00, 31.29it/s]\n",
      "> Eval on experience 0 (Task 0) from train stream ended.\n",
      "\tTop1_Acc_Exp/eval_phase/train_stream/Task000/Exp000 = 0.9645\n",
      "-- Starting eval on experience 1 (Task 1) from train stream --\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 127/127 [00:03<00:00, 31.78it/s]\n",
      "> Eval on experience 1 (Task 1) from train stream ended.\n",
      "\tTop1_Acc_Exp/eval_phase/train_stream/Task001/Exp001 = 0.5309\n",
      "-- >> End of eval phase << --\n",
      "\tTop1_Acc_Stream/eval_phase/train_stream/Task000 = 0.9645\n",
      "\tTop1_Acc_Stream/eval_phase/train_stream/Task001 = 0.5309\n",
      "-- >> End of training phase << --\n",
      "-- >> Start of training phase << --\n",
      "-- >> Start of eval phase << --\n",
      "-- Starting eval on experience 0 (Task 0) from train stream --\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 114/114 [00:03<00:00, 31.58it/s]\n",
      "> Eval on experience 0 (Task 0) from train stream ended.\n",
      "\tTop1_Acc_Exp/eval_phase/train_stream/Task000/Exp000 = 0.9645\n",
      "-- Starting eval on experience 1 (Task 1) from train stream --\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 127/127 [00:04<00:00, 31.31it/s]\n",
      "> Eval on experience 1 (Task 1) from train stream ended.\n",
      "\tTop1_Acc_Exp/eval_phase/train_stream/Task001/Exp001 = 0.5309\n",
      "-- >> End of eval phase << --\n",
      "\tTop1_Acc_Stream/eval_phase/train_stream/Task000 = 0.9645\n",
      "\tTop1_Acc_Stream/eval_phase/train_stream/Task001 = 0.5309\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 127/127 [00:04<00:00, 26.22it/s]\n",
      "Epoch 0 ended.\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task001 = 0.9485\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task001 = 1.0000\n",
      "-- >> Start of eval phase << --\n",
      "-- Starting eval on experience 0 (Task 0) from train stream --\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 114/114 [00:04<00:00, 28.32it/s]\n",
      "> Eval on experience 0 (Task 0) from train stream ended.\n",
      "\tTop1_Acc_Exp/eval_phase/train_stream/Task000/Exp000 = 0.9511\n",
      "-- Starting eval on experience 1 (Task 1) from train stream --\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 127/127 [00:04<00:00, 26.17it/s]\n",
      "> Eval on experience 1 (Task 1) from train stream ended.\n",
      "\tTop1_Acc_Exp/eval_phase/train_stream/Task001/Exp001 = 0.9817\n",
      "-- >> End of eval phase << --\n",
      "\tTop1_Acc_Stream/eval_phase/train_stream/Task000 = 0.9511\n",
      "\tTop1_Acc_Stream/eval_phase/train_stream/Task001 = 0.9817\n",
      "-- >> End of training phase << --\n"
     ]
    }
   ],
   "source": [
    "from avalanche.training.plugins import EvaluationPlugin\n",
    "from avalanche.logging import InteractiveLogger\n",
    "from avalanche.evaluation.metrics import accuracy_metrics\n",
    "\n",
    "# model\n",
    "model = as_multitask(MLP(), 'classifier')\n",
    "optimizer = SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "criterion = CrossEntropyLoss()\n",
    "\n",
    "evaluator = EvaluationPlugin(\n",
    "    accuracy_metrics(minibatch=True, epoch=True, experience=True, stream=True),\n",
    "    loggers=[InteractiveLogger()],\n",
    "    suppress_warnings=True\n",
    ")\n",
    "\n",
    "# strategy\n",
    "cl_strategy = Naive(\n",
    "    model=model, \n",
    "    optimizer=optimizer, \n",
    "    criterion=criterion,\n",
    "    train_mb_size=100, \n",
    "    train_epochs=1, \n",
    "    eval_mb_size=100,\n",
    "    eval_every=1,  # how often you want the evaluation during training\n",
    "    evaluator=evaluator\n",
    ")\n",
    "\n",
    "for exp in benchmark.train_stream[:2]:\n",
    "    cl_strategy.train(exp, eval_streams=[benchmark.train_stream[:2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(<function avalanche.training.plugins.evaluation.EvaluationPlugin.__init__.<locals>.<lambda>()>,\n",
       "            {'Top1_Acc_Exp/eval_phase/train_stream/Task000/Exp000': ([0,\n",
       "               114,\n",
       "               114,\n",
       "               241],\n",
       "              [0.47808448716818064,\n",
       "               0.9645471381956081,\n",
       "               0.9645471381956081,\n",
       "               0.9510538848222947]),\n",
       "             'Top1_Acc_Exp/eval_phase/train_stream/Task001/Exp001': ([0,\n",
       "               114,\n",
       "               114,\n",
       "               241],\n",
       "              [0.5308661417322834,\n",
       "               0.5308661417322834,\n",
       "               0.5308661417322834,\n",
       "               0.981732283464567]),\n",
       "             'Top1_Acc_Stream/eval_phase/train_stream/Task000': ([0,\n",
       "               114,\n",
       "               114,\n",
       "               241],\n",
       "              [0.47808448716818064,\n",
       "               0.9645471381956081,\n",
       "               0.9645471381956081,\n",
       "               0.9510538848222947]),\n",
       "             'Top1_Acc_Stream/eval_phase/train_stream/Task001': ([0,\n",
       "               114,\n",
       "               114,\n",
       "               241],\n",
       "              [0.5308661417322834,\n",
       "               0.5308661417322834,\n",
       "               0.5308661417322834,\n",
       "               0.981732283464567]),\n",
       "             'Top1_Acc_MB/train_phase/train_stream/Task000': ([0,\n",
       "               1,\n",
       "               2,\n",
       "               3,\n",
       "               4,\n",
       "               5,\n",
       "               6,\n",
       "               7,\n",
       "               8,\n",
       "               9,\n",
       "               10,\n",
       "               11,\n",
       "               12,\n",
       "               13,\n",
       "               14,\n",
       "               15,\n",
       "               16,\n",
       "               17,\n",
       "               18,\n",
       "               19,\n",
       "               20,\n",
       "               21,\n",
       "               22,\n",
       "               23,\n",
       "               24,\n",
       "               25,\n",
       "               26,\n",
       "               27,\n",
       "               28,\n",
       "               29,\n",
       "               30,\n",
       "               31,\n",
       "               32,\n",
       "               33,\n",
       "               34,\n",
       "               35,\n",
       "               36,\n",
       "               37,\n",
       "               38,\n",
       "               39,\n",
       "               40,\n",
       "               41,\n",
       "               42,\n",
       "               43,\n",
       "               44,\n",
       "               45,\n",
       "               46,\n",
       "               47,\n",
       "               48,\n",
       "               49,\n",
       "               50,\n",
       "               51,\n",
       "               52,\n",
       "               53,\n",
       "               54,\n",
       "               55,\n",
       "               56,\n",
       "               57,\n",
       "               58,\n",
       "               59,\n",
       "               60,\n",
       "               61,\n",
       "               62,\n",
       "               63,\n",
       "               64,\n",
       "               65,\n",
       "               66,\n",
       "               67,\n",
       "               68,\n",
       "               69,\n",
       "               70,\n",
       "               71,\n",
       "               72,\n",
       "               73,\n",
       "               74,\n",
       "               75,\n",
       "               76,\n",
       "               77,\n",
       "               78,\n",
       "               79,\n",
       "               80,\n",
       "               81,\n",
       "               82,\n",
       "               83,\n",
       "               84,\n",
       "               85,\n",
       "               86,\n",
       "               87,\n",
       "               88,\n",
       "               89,\n",
       "               90,\n",
       "               91,\n",
       "               92,\n",
       "               93,\n",
       "               94,\n",
       "               95,\n",
       "               96,\n",
       "               97,\n",
       "               98,\n",
       "               99,\n",
       "               100,\n",
       "               101,\n",
       "               102,\n",
       "               103,\n",
       "               104,\n",
       "               105,\n",
       "               106,\n",
       "               107,\n",
       "               108,\n",
       "               109,\n",
       "               110,\n",
       "               111,\n",
       "               112,\n",
       "               113],\n",
       "              [0.54,\n",
       "               0.61,\n",
       "               0.58,\n",
       "               0.62,\n",
       "               0.65,\n",
       "               0.68,\n",
       "               0.61,\n",
       "               0.79,\n",
       "               0.72,\n",
       "               0.72,\n",
       "               0.72,\n",
       "               0.7,\n",
       "               0.79,\n",
       "               0.86,\n",
       "               0.77,\n",
       "               0.87,\n",
       "               0.82,\n",
       "               0.81,\n",
       "               0.67,\n",
       "               0.77,\n",
       "               0.81,\n",
       "               0.84,\n",
       "               0.88,\n",
       "               0.86,\n",
       "               0.89,\n",
       "               0.9,\n",
       "               0.86,\n",
       "               0.86,\n",
       "               0.88,\n",
       "               0.86,\n",
       "               0.87,\n",
       "               0.93,\n",
       "               0.93,\n",
       "               0.93,\n",
       "               0.9,\n",
       "               0.93,\n",
       "               0.94,\n",
       "               0.9,\n",
       "               0.94,\n",
       "               0.92,\n",
       "               0.93,\n",
       "               0.9,\n",
       "               0.88,\n",
       "               0.93,\n",
       "               0.94,\n",
       "               0.91,\n",
       "               0.87,\n",
       "               0.95,\n",
       "               0.95,\n",
       "               0.95,\n",
       "               0.96,\n",
       "               0.96,\n",
       "               0.98,\n",
       "               0.92,\n",
       "               0.96,\n",
       "               0.95,\n",
       "               0.92,\n",
       "               0.96,\n",
       "               0.92,\n",
       "               0.97,\n",
       "               0.97,\n",
       "               0.95,\n",
       "               0.95,\n",
       "               0.91,\n",
       "               0.92,\n",
       "               0.98,\n",
       "               0.98,\n",
       "               0.92,\n",
       "               0.98,\n",
       "               0.96,\n",
       "               0.95,\n",
       "               0.99,\n",
       "               0.97,\n",
       "               0.98,\n",
       "               0.98,\n",
       "               0.98,\n",
       "               0.96,\n",
       "               0.93,\n",
       "               0.91,\n",
       "               0.95,\n",
       "               0.97,\n",
       "               0.98,\n",
       "               0.97,\n",
       "               0.98,\n",
       "               0.98,\n",
       "               0.95,\n",
       "               0.97,\n",
       "               0.98,\n",
       "               0.96,\n",
       "               0.97,\n",
       "               0.99,\n",
       "               0.96,\n",
       "               0.95,\n",
       "               0.96,\n",
       "               0.93,\n",
       "               0.96,\n",
       "               0.96,\n",
       "               0.97,\n",
       "               0.96,\n",
       "               0.98,\n",
       "               0.99,\n",
       "               0.91,\n",
       "               0.97,\n",
       "               0.96,\n",
       "               0.94,\n",
       "               0.97,\n",
       "               0.98,\n",
       "               0.97,\n",
       "               0.95,\n",
       "               0.98,\n",
       "               0.97,\n",
       "               0.99,\n",
       "               0.97,\n",
       "               1.0]),\n",
       "             'Top1_Acc_Epoch/train_phase/train_stream/Task000': ([114],\n",
       "              [0.9015786224534792]),\n",
       "             'Top1_Acc_MB/train_phase/train_stream/Task001': ([114,\n",
       "               115,\n",
       "               116,\n",
       "               117,\n",
       "               118,\n",
       "               119,\n",
       "               120,\n",
       "               121,\n",
       "               122,\n",
       "               123,\n",
       "               124,\n",
       "               125,\n",
       "               126,\n",
       "               127,\n",
       "               128,\n",
       "               129,\n",
       "               130,\n",
       "               131,\n",
       "               132,\n",
       "               133,\n",
       "               134,\n",
       "               135,\n",
       "               136,\n",
       "               137,\n",
       "               138,\n",
       "               139,\n",
       "               140,\n",
       "               141,\n",
       "               142,\n",
       "               143,\n",
       "               144,\n",
       "               145,\n",
       "               146,\n",
       "               147,\n",
       "               148,\n",
       "               149,\n",
       "               150,\n",
       "               151,\n",
       "               152,\n",
       "               153,\n",
       "               154,\n",
       "               155,\n",
       "               156,\n",
       "               157,\n",
       "               158,\n",
       "               159,\n",
       "               160,\n",
       "               161,\n",
       "               162,\n",
       "               163,\n",
       "               164,\n",
       "               165,\n",
       "               166,\n",
       "               167,\n",
       "               168,\n",
       "               169,\n",
       "               170,\n",
       "               171,\n",
       "               172,\n",
       "               173,\n",
       "               174,\n",
       "               175,\n",
       "               176,\n",
       "               177,\n",
       "               178,\n",
       "               179,\n",
       "               180,\n",
       "               181,\n",
       "               182,\n",
       "               183,\n",
       "               184,\n",
       "               185,\n",
       "               186,\n",
       "               187,\n",
       "               188,\n",
       "               189,\n",
       "               190,\n",
       "               191,\n",
       "               192,\n",
       "               193,\n",
       "               194,\n",
       "               195,\n",
       "               196,\n",
       "               197,\n",
       "               198,\n",
       "               199,\n",
       "               200,\n",
       "               201,\n",
       "               202,\n",
       "               203,\n",
       "               204,\n",
       "               205,\n",
       "               206,\n",
       "               207,\n",
       "               208,\n",
       "               209,\n",
       "               210,\n",
       "               211,\n",
       "               212,\n",
       "               213,\n",
       "               214,\n",
       "               215,\n",
       "               216,\n",
       "               217,\n",
       "               218,\n",
       "               219,\n",
       "               220,\n",
       "               221,\n",
       "               222,\n",
       "               223,\n",
       "               224,\n",
       "               225,\n",
       "               226,\n",
       "               227,\n",
       "               228,\n",
       "               229,\n",
       "               230,\n",
       "               231,\n",
       "               232,\n",
       "               233,\n",
       "               234,\n",
       "               235,\n",
       "               236,\n",
       "               237,\n",
       "               238,\n",
       "               239,\n",
       "               240],\n",
       "              [0.52,\n",
       "               0.44,\n",
       "               0.66,\n",
       "               0.59,\n",
       "               0.65,\n",
       "               0.74,\n",
       "               0.83,\n",
       "               0.85,\n",
       "               0.89,\n",
       "               0.9,\n",
       "               0.79,\n",
       "               0.89,\n",
       "               0.91,\n",
       "               0.95,\n",
       "               0.92,\n",
       "               0.94,\n",
       "               0.96,\n",
       "               0.95,\n",
       "               0.99,\n",
       "               0.94,\n",
       "               0.99,\n",
       "               0.98,\n",
       "               0.95,\n",
       "               0.96,\n",
       "               0.97,\n",
       "               0.95,\n",
       "               0.98,\n",
       "               0.95,\n",
       "               0.97,\n",
       "               0.98,\n",
       "               0.99,\n",
       "               0.97,\n",
       "               0.97,\n",
       "               0.98,\n",
       "               0.96,\n",
       "               0.98,\n",
       "               0.96,\n",
       "               0.95,\n",
       "               0.94,\n",
       "               0.97,\n",
       "               0.95,\n",
       "               0.94,\n",
       "               0.97,\n",
       "               0.99,\n",
       "               0.98,\n",
       "               0.97,\n",
       "               0.96,\n",
       "               0.96,\n",
       "               0.96,\n",
       "               0.97,\n",
       "               0.98,\n",
       "               0.96,\n",
       "               0.98,\n",
       "               0.98,\n",
       "               0.93,\n",
       "               0.99,\n",
       "               0.96,\n",
       "               0.94,\n",
       "               0.98,\n",
       "               1.0,\n",
       "               0.98,\n",
       "               0.97,\n",
       "               0.95,\n",
       "               0.97,\n",
       "               0.99,\n",
       "               0.98,\n",
       "               0.95,\n",
       "               0.97,\n",
       "               0.98,\n",
       "               0.97,\n",
       "               0.97,\n",
       "               0.94,\n",
       "               0.97,\n",
       "               0.98,\n",
       "               0.97,\n",
       "               0.98,\n",
       "               0.99,\n",
       "               0.97,\n",
       "               0.98,\n",
       "               0.97,\n",
       "               0.98,\n",
       "               0.97,\n",
       "               0.97,\n",
       "               0.99,\n",
       "               0.98,\n",
       "               0.98,\n",
       "               0.96,\n",
       "               0.98,\n",
       "               1.0,\n",
       "               0.98,\n",
       "               1.0,\n",
       "               0.99,\n",
       "               0.99,\n",
       "               0.95,\n",
       "               0.94,\n",
       "               1.0,\n",
       "               0.99,\n",
       "               0.99,\n",
       "               0.98,\n",
       "               0.98,\n",
       "               1.0,\n",
       "               0.98,\n",
       "               0.99,\n",
       "               1.0,\n",
       "               0.99,\n",
       "               0.99,\n",
       "               0.96,\n",
       "               0.97,\n",
       "               0.98,\n",
       "               0.98,\n",
       "               0.96,\n",
       "               0.99,\n",
       "               0.97,\n",
       "               0.98,\n",
       "               0.98,\n",
       "               0.94,\n",
       "               0.99,\n",
       "               0.96,\n",
       "               0.97,\n",
       "               0.98,\n",
       "               0.98,\n",
       "               0.96,\n",
       "               0.95,\n",
       "               0.99,\n",
       "               0.99,\n",
       "               0.99,\n",
       "               1.0]),\n",
       "             'Top1_Acc_Epoch/train_phase/train_stream/Task001': ([241],\n",
       "              [0.948503937007874])})"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator.get_all_metrics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Adding Plugins\n",
    "\n",
    "Most continual learning strategies follow roughly the same training/evaluation loops, i.e. a simple naive strategy (a.k.a. finetuning) augmented with additional behavior to counteract catastrophic forgetting. The plugin systems in Avalanche is designed to easily augment continual learning strategies with custom behavior, without having to rewrite the training loop from scratch. Avalanche strategies accept an optional list of `plugins` that will be executed during the training/evaluation loops.\n",
    "\n",
    "For example, early stopping is implemented as a plugin:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from avalanche.training.plugins import EarlyStoppingPlugin\n",
    "\n",
    "strategy = Naive(\n",
    "    model, optimizer, criterion,\n",
    "    plugins=[EarlyStoppingPlugin(patience=10, val_stream_name='train')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "In Avalanche, most continual learning strategies are implemented using plugins, which makes it easy to combine them together. For example, it is extremely easy to create a hybrid strategy that combines replay and EWC together by passing the appropriate `plugins` list to the `SupervisedTemplate`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from avalanche.training.templates import SupervisedTemplate\n",
    "from avalanche.training.plugins import ReplayPlugin, EWCPlugin\n",
    "\n",
    "replay = ReplayPlugin(mem_size=100)\n",
    "ewc = EWCPlugin(ewc_lambda=0.001)\n",
    "strategy = SupervisedTemplate(\n",
    "    model, optimizer, criterion,\n",
    "    plugins=[replay, ewc])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Beware that most strategy plugins modify the internal state. As a result, not all the strategy plugins can be combined together. For example, it does not make sense to use multiple replay plugins since they will try to modify the same strategy variables (mini-batches, dataloaders), and therefore they will be in conflict."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example: Replay Buffers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max buffer size: 30, current size: 0\n"
     ]
    }
   ],
   "source": [
    "from avalanche.training.storage_policy import ReservoirSamplingBuffer\n",
    "from types import SimpleNamespace\n",
    "\n",
    "benchmark = SplitMNIST(5, return_task_id=False)\n",
    "storage_p = ReservoirSamplingBuffer(max_size=30)\n",
    "\n",
    "print(f\"Max buffer size: {storage_p.max_size}, current size: {len(storage_p.buffer)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max buffer size: 30, current size: 0\n",
      "Max buffer size: 30, current size: 30\n",
      "class targets: [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7]\n",
      "\n",
      "Max buffer size: 30, current size: 30\n",
      "class targets: [5, 5, 5, 5, 5, 5, 5, 5, 7, 7, 7, 7, 7, 7, 7, 2, 2, 2, 2, 2, 2, 2, 2, 6, 6, 6, 6, 6, 6, 6]\n",
      "\n",
      "Max buffer size: 30, current size: 30\n",
      "class targets: [5, 5, 5, 5, 5, 7, 7, 7, 7, 7, 2, 2, 2, 2, 2, 6, 6, 6, 6, 6, 4, 4, 4, 4, 4, 1, 1, 1, 1, 1]\n",
      "\n",
      "Max buffer size: 30, current size: 30\n",
      "class targets: [5, 5, 5, 5, 7, 7, 7, 2, 2, 2, 2, 6, 6, 6, 6, 4, 4, 4, 4, 1, 1, 1, 1, 0, 0, 0, 0, 9, 9, 9]\n",
      "\n",
      "Max buffer size: 30, current size: 30\n",
      "class targets: [5, 5, 5, 7, 7, 7, 2, 2, 2, 6, 6, 6, 4, 4, 4, 1, 1, 1, 0, 0, 0, 9, 9, 9, 3, 3, 3, 8, 8, 8]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from avalanche.training.storage_policy import ParametricBuffer, RandomExemplarsSelectionStrategy\n",
    "from types import SimpleNamespace\n",
    "\n",
    "\n",
    "storage_p = ParametricBuffer(\n",
    "    max_size=30,\n",
    "    groupby='class',\n",
    "    selection_strategy=RandomExemplarsSelectionStrategy()\n",
    ")\n",
    "\n",
    "print(f\"Max buffer size: {storage_p.max_size}, current size: {len(storage_p.buffer)}\")\n",
    "for i in range(5):\n",
    "    # you can use a SimpleNamespace if you want to use Avalanche components with your own code.\n",
    "    strategy_state = SimpleNamespace(experience=benchmark.train_stream[i])\n",
    "    storage_p.update(strategy_state)\n",
    "    print(f\"Max buffer size: {storage_p.max_size}, current size: {len(storage_p.buffer)}\")\n",
    "    print(f\"class targets: {storage_p.buffer.targets}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 🤝 Run it on Google Colab\n",
    "\n",
    "You can run _this chapter_ and play with it on Google Colaboratory: [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/AntonioCarta/avalanche-demo/blob/main/avl_demo.ipynb)\n",
    "\n",
    "https://github.com/AntonioCarta/avalanche-demo/blob/main/avl_demo.ipynb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
